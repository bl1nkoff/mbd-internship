# Тестовое задание для стажёра команды Mobile BigData от Блинкова Сергея
## Задание
Необходимо разработать сервис, который будет получать данные по уровню сигнала от пользователей и отображать в веб-приложении на карте в тайлах S2 уровня 15 две агрегатные метрики — средний уровень сигнала на тайл и количество уникальных пользователей в тайле.

## Высокоуровневое описание реализации
Пути url/data ожидаем данные, в виде координат, user id и уровня сигнала. Для скорости хендлера просто проверяем это на заданные условия и отправляем в "сырую" базу данных
Когда по адресу /map приходят две крайние координаты видимого поля карты, запрашиваем обработку данных в "сырой" базе данных. По координатам из этих данных определяем клетку s2 15 уровня. В обычной базе хранятся данные отсортированные по клеткам, поэтому проверяем есть ли у нас такая клетка, если есть, то дополняем информацию о ней, если нет, то записываем, крайние координаты, координату центра(для быстрого определения находится ли тайл в зоне видимости, хотя можно сделать отбор грубее и просто проверять по дному из углов, конечно, можно и все углы проверять, но это неоправданно тяжелее) и наши данные от пользователя. В ответ на запрос отправляем массив клеток, который рисуем на гугл картах, подключенных через JS API. Чекбоксы снизу отвечают за отображаемую метрику, так же для оптимизации обновление клеток только по кнопке.
Так же оставил автозаполнение случайными данными через страничку с картой - снизу кнопки запуска и остановки интервала с выводом в консоль. 

## Что получилось реализовать
* Приём данных заданной формы
```json
{
    "lat": 59.9355,
    "lon": 30.325623,
    "user_id": "98ea80cf-268a-474f-9ebb-5cc49b55365b",
    "signal": 20.68
}
```
* Отображение веб странички с картой
* Отображение тайлов на карте
* Изменение режима отображаемой метрики
* Вывод тайлов только в видимую область
* LvlDB
* Соблюдение заданных форматов данных

## Что не получилось реализовать
* Реализация очереди запросов, для повышения скорости запросов в секунду
* Dockerfile (никогда с ним не работал, попытался, но он не может найти исполнительный файл, хотя ровно такой же алгоритм с FROM python и файлом на питоне работает)

## Главная нереализованная проблема - запросы в минуту
С самого начала предположил, что запросы нужно отправлять в некую очередь, где потом уже своевременно обрабатывать их. Если не ошибаюсь с термином, то этим занимается диспатчер. Сторонняя библиотека так и не заработала нормально. Скорость чуть выше обычной. Закомментировал её использование, раз так просило задание, а особого результата это так и не дало. 

## Заполнение карты
Проект на гитхабе без БД, так что нужно предварительно немного их заполнить. Это можно сделать на /map. Ход заполнения отображается в консоли. После 5 ошибок интервал запросов автоматически выключается.